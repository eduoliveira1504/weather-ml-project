"""
UrbanShield AI - Treinamento da U-Net para Segmenta√ß√£o de Sat√©lite

Este script implementa o treinamento completo da U-Net com:
- Fun√ß√£o de perda combinada (Dice Loss + Binary Cross Entropy)
- M√©tricas de avalia√ß√£o (Accuracy, IoU, Dice Score)
- Salvamento do melhor modelo
- Valida√ß√£o a cada √©poca
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import random_split
from tqdm import tqdm
import os
from pathlib import Path

# Importar nossos m√≥dulos
from unet_model import UNet
from dataset import SatelliteDataset, get_transforms

# ==========================
# CONFIGURA√á√ïES
# ==========================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
LEARNING_RATE = 1e-4
BATCH_SIZE = 8
NUM_EPOCHS = 50
NUM_WORKERS = 2
IMAGE_HEIGHT = 256
IMAGE_WIDTH = 256
PIN_MEMORY = True
LOAD_MODEL = False

# Diret√≥rios
DATA_DIR = Path("data/raw/deepglobe/train")
MODEL_DIR = Path("models/unet")
MODEL_DIR.mkdir(parents=True, exist_ok=True)


# ==========================
# FUN√á√ïES DE PERDA
# ==========================

class DiceLoss(nn.Module):
    """
    Dice Loss para segmenta√ß√£o
    
    Dice Score mede sobreposi√ß√£o entre predi√ß√£o e ground truth.
    F√≥rmula: 2 * |A ‚à© B| / (|A| + |B|)
    
    Vantagens:
    - Funciona bem com classes desbalanceadas
    - Penaliza erros em regi√µes pequenas
    """
    def __init__(self, smooth=1e-6):
        super(DiceLoss, self).__init__()
        self.smooth = smooth
    
    def forward(self, predictions, targets):
        # Aplicar sigmoid para converter logits em probabilidades
        predictions = torch.sigmoid(predictions)
        
        # Flatten (achatar) para calcular interse√ß√£o
        predictions = predictions.view(-1)
        targets = targets.view(-1)
        
        # Calcular interse√ß√£o e uni√£o
        intersection = (predictions * targets).sum()
        dice_score = (2.0 * intersection + self.smooth) / (
            predictions.sum() + targets.sum() + self.smooth
        )
        
        # Retornar 1 - dice (loss)
        return 1 - dice_score


class DiceBCELoss(nn.Module):
    """
    Combina√ß√£o de Dice Loss + Binary Cross Entropy
    
    BCE: Penaliza predi√ß√µes incorretas pixel por pixel
    Dice: Penaliza falta de sobreposi√ß√£o global
    
    Combina√ß√£o funciona melhor que cada uma isolada!
    """
    def __init__(self):
        super(DiceBCELoss, self).__init__()
        self.dice = DiceLoss()
        self.bce = nn.BCEWithLogitsLoss()
    
    def forward(self, predictions, targets):
        dice_loss = self.dice(predictions, targets)
        bce_loss = self.bce(predictions, targets)
        return dice_loss + bce_loss


# ==========================
# M√âTRICAS DE AVALIA√á√ÉO
# ==========================

def calculate_accuracy(predictions, targets):
    """Acur√°cia: % de pixels classificados corretamente"""
    predictions = torch.sigmoid(predictions)
    predictions = (predictions > 0.5).float()
    correct = (predictions == targets).float().sum()
    total = targets.numel()
    return (correct / total).item()


def calculate_iou(predictions, targets, threshold=0.5):
    """
    IoU (Intersection over Union) ou Jaccard Index
    Mede sobreposi√ß√£o: |A ‚à© B| / |A ‚à™ B|
    """
    predictions = torch.sigmoid(predictions)
    predictions = (predictions > threshold).float()
    
    intersection = (predictions * targets).sum()
    union = predictions.sum() + targets.sum() - intersection
    
    iou = (intersection + 1e-6) / (union + 1e-6)
    return iou.item()


def calculate_dice_score(predictions, targets):
    """
    Dice Score: 2 * |A ‚à© B| / (|A| + |B|)
    Semelhante ao IoU, mas pondera interse√ß√£o 2x
    """
    predictions = torch.sigmoid(predictions)
    predictions = (predictions > 0.5).float()
    
    intersection = (predictions * targets).sum()
    dice = (2.0 * intersection + 1e-6) / (
        predictions.sum() + targets.sum() + 1e-6
    )
    return dice.item()


# ==========================
# TREINAMENTO E VALIDA√á√ÉO
# ==========================

def train_one_epoch(loader, model, optimizer, loss_fn, device):
    """
    Treina o modelo por uma √©poca
    
    Args:
        loader: DataLoader com dados de treino
        model: Modelo U-Net
        optimizer: Otimizador (Adam)
        loss_fn: Fun√ß√£o de perda
        device: 'cuda' ou 'cpu'
    
    Returns:
        dict: M√©tricas m√©dias da √©poca
    """
    model.train()
    
    loop = tqdm(loader, desc="Treinando")
    
    epoch_loss = 0
    epoch_acc = 0
    epoch_iou = 0
    epoch_dice = 0
    
    for batch_idx, (images, masks) in enumerate(loop):
        images = images.to(device)
        masks = masks.to(device)
        
        # Forward pass
        predictions = model(images)
        loss = loss_fn(predictions, masks)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # Calcular m√©tricas
        acc = calculate_accuracy(predictions, masks)
        iou = calculate_iou(predictions, masks)
        dice = calculate_dice_score(predictions, masks)
        
        epoch_loss += loss.item()
        epoch_acc += acc
        epoch_iou += iou
        epoch_dice += dice
        
        # Atualizar barra de progresso
        loop.set_postfix(
            loss=loss.item(),
            acc=acc,
            iou=iou,
            dice=dice
        )
    
    # M√©dias
    num_batches = len(loader)
    return {
        'loss': epoch_loss / num_batches,
        'accuracy': epoch_acc / num_batches,
        'iou': epoch_iou / num_batches,
        'dice': epoch_dice / num_batches
    }


def validate(loader, model, loss_fn, device):
    """
    Valida o modelo no conjunto de valida√ß√£o
    
    Args:
        loader: DataLoader com dados de valida√ß√£o
        model: Modelo U-Net
        loss_fn: Fun√ß√£o de perda
        device: 'cuda' ou 'cpu'
    
    Returns:
        dict: M√©tricas m√©dias de valida√ß√£o
    """
    model.eval()
    
    val_loss = 0
    val_acc = 0
    val_iou = 0
    val_dice = 0
    
    with torch.no_grad():
        for images, masks in tqdm(loader, desc="Validando"):
            images = images.to(device)
            masks = masks.to(device)
            
            predictions = model(images)
            loss = loss_fn(predictions, masks)
            
            val_loss += loss.item()
            val_acc += calculate_accuracy(predictions, masks)
            val_iou += calculate_iou(predictions, masks)
            val_dice += calculate_dice_score(predictions, masks)
    
    num_batches = len(loader)
    return {
        'loss': val_loss / num_batches,
        'accuracy': val_acc / num_batches,
        'iou': val_iou / num_batches,
        'dice': val_dice / num_batches
    }


def save_checkpoint(state, filename="checkpoint.pth.tar"):
    """Salva checkpoint do modelo"""
    print(f"üíæ Salvando checkpoint: {filename}")
    torch.save(state, filename)


def load_checkpoint(checkpoint, model, optimizer):
    """Carrega checkpoint do modelo"""
    print(f"üìÇ Carregando checkpoint...")
    model.load_state_dict(checkpoint["state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer"])


# ==========================
# FUN√á√ÉO PRINCIPAL
# ==========================

def main():
    print("=" * 70)
    print("üåç URBANSHIELD AI - TREINAMENTO U-NET")
    print("=" * 70)
    
    # ========== 1. PREPARAR DADOS ==========
    print(f"\nüìÇ Carregando dataset...")
    
    # Dataset completo
    full_dataset = SatelliteDataset(
        image_dir=str(DATA_DIR / "images"),
        mask_dir=str(DATA_DIR / "masks"),
        transform=get_transforms(train=True)
    )
    
    # Dividir em treino (80%) e valida√ß√£o (20%)
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    
    train_dataset, val_dataset = random_split(
        full_dataset, 
        [train_size, val_size]
    )
    
    # Criar DataLoaders
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=NUM_WORKERS,
        pin_memory=PIN_MEMORY
    )
    
    val_loader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS,
        pin_memory=PIN_MEMORY
    )
    
    print(f"‚úÖ Dataset preparado:")
    print(f"   Treino: {train_size} imagens ({len(train_loader)} batches)")
    print(f"   Valida√ß√£o: {val_size} imagens ({len(val_loader)} batches)")
    
    # ========== 2. CRIAR MODELO ==========
    print(f"\nüß† Inicializando U-Net...")
    model = UNet(in_channels=3, out_channels=1).to(DEVICE)
    
    print(f"‚úÖ Modelo criado:")
    print(f"   Device: {DEVICE}")
    print(f"   Par√¢metros: {sum(p.numel() for p in model.parameters()):,}")
    
    # ========== 3. OTIMIZADOR E LOSS ==========
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    loss_fn = DiceBCELoss()
    
    print(f"\n‚öôÔ∏è  Configura√ß√µes de treino:")
    print(f"   Learning Rate: {LEARNING_RATE}")
    print(f"   Batch Size: {BATCH_SIZE}")
    print(f"   √âpocas: {NUM_EPOCHS}")
    print(f"   Loss: Dice + BCE")
    
    # Carregar checkpoint se existir
    if LOAD_MODEL:
        checkpoint_path = MODEL_DIR / "checkpoint.pth.tar"
        if checkpoint_path.exists():
            load_checkpoint(torch.load(checkpoint_path), model, optimizer)
    
    # ========== 4. LOOP DE TREINAMENTO ==========
    print("\n" + "=" * 70)
    print("üöÄ INICIANDO TREINAMENTO")
    print("=" * 70)
    
    best_dice = 0.0
    
    for epoch in range(NUM_EPOCHS):
        print(f"\nüìä √âPOCA {epoch+1}/{NUM_EPOCHS}")
        print("-" * 70)
        
        # Treinar
        train_metrics = train_one_epoch(
            train_loader, model, optimizer, loss_fn, DEVICE
        )
        
        # Validar
        val_metrics = validate(val_loader, model, loss_fn, DEVICE)
        
        # Exibir m√©tricas
        print(f"\nüìà RESULTADOS DA √âPOCA {epoch+1}:")
        print(f"   TREINO    ‚Üí Loss: {train_metrics['loss']:.4f} | "
              f"Acc: {train_metrics['accuracy']:.4f} | "
              f"IoU: {train_metrics['iou']:.4f} | "
              f"Dice: {train_metrics['dice']:.4f}")
        print(f"   VALIDA√á√ÉO ‚Üí Loss: {val_metrics['loss']:.4f} | "
              f"Acc: {val_metrics['accuracy']:.4f} | "
              f"IoU: {val_metrics['iou']:.4f} | "
              f"Dice: {val_metrics['dice']:.4f}")
        
        # Salvar melhor modelo
        if val_metrics['dice'] > best_dice:
            best_dice = val_metrics['dice']
            checkpoint = {
                "state_dict": model.state_dict(),
                "optimizer": optimizer.state_dict(),
                "epoch": epoch,
                "best_dice": best_dice
            }
            save_checkpoint(checkpoint, MODEL_DIR / "best_model.pth.tar")
            print(f"   ‚≠ê Novo melhor modelo! Dice: {best_dice:.4f}")
        
        # Salvar checkpoint regular
        checkpoint = {
            "state_dict": model.state_dict(),
            "optimizer": optimizer.state_dict(),
            "epoch": epoch
        }
        save_checkpoint(checkpoint, MODEL_DIR / "checkpoint.pth.tar")
    
    # ========== 5. FINALIZA√á√ÉO ==========
    print("\n" + "=" * 70)
    print("‚úÖ TREINAMENTO CONCLU√çDO!")
    print("=" * 70)
    print(f"üèÜ Melhor Dice Score: {best_dice:.4f}")
    print(f"üíæ Modelo salvo em: {MODEL_DIR / 'best_model.pth.tar'}")
    print("\nüìå Pr√≥ximo passo: python src/forecasting/train_lstm.py")


if __name__ == "__main__":
    main()
